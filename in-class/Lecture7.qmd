---
title: "Lecture 7"
author: Andrew Kerr
format: html
embed-resources: true
---

## Activity 1: Fill out this table

| Phrase | Symbols | Words |
|----------------------|---------------------|-----------------------------|
| $x_t$ is white noise | $N(0, \sigma_w^2)$ | Normally distributed with mean 0 and variance $\sigma_w^2$. |
| $x_t$ is stationary in the mean | $E(x_t) = \mu$ | The mean of $x_t$ is constant over time. |
| $x_t$ is stationary in the autocovariance | $\gamma(s) = E[(x_t - \mu)(x_{t+s} - \mu)]$ | The autocovariance function depends only on the lag $s$, not time $t$. |
| $x_t$ is stationary | $E(x_t) = \mu$, $\gamma(s)$ | $x_t$ has constant mean, variance, and autocovariance over time. |
| $x_t$ has no temporal structure | $\gamma(s) = 0$ for $s \neq 0$ | There is no dependence between $x_t$ values at different times. |

## Activity 2: Modeling time series

I have a data set with 5 different time series.

The possible sources/models are:

-   white noise,

-   a moving average of some order $p$ of white noise,

-   a simulated trend stationary model where the temporal structure (mean function) is a simple linear regression line, and

-   a real data set

-   one of the categories is duplicated

Try to identify which is which by completing the following steps for each series:

::: callout-note
## Attempting to coerce stationarity

1.  Download the data `time_series.csv` from Canvas and create a sub-folder in your `Lecture7` folder called `Data`. Read in the data. Extract `y1`, the first time series, and name it `x_t`. Save it in a data frame called `all_ts`.
2.  Plot the time series data set using both points and lines.
3.  In separate plot, again plot the time series as just points and also plot a moving average smoother over the time series (use any $p$ you'd like, but use a symmetric one). Create a data frame called `all_ts` with the original time series and the moving average smoother.
4.  *Detrend* the time series with respect to the moving average estimate and plot the de-trended time series as points and lines. Save the detrended series in `all_ts`.
5.  In a separate plot, again plot the time series as points and also plot a simple linear regression line using `time(x)` where `x` is the time series you are analyzing. Add the fitted values to the `all_ts` data frame.
6.  *Detrend* the time series with respect to the regression and plot and save the detrended series (save in the `all_ts` data frame).
7.  *Difference* the time series, plot as points and lines and save the differenced series.
8.  Run `par(mfrow = c(2,3))` and then re-run the plotting code for all 6 plots you just made in steps 1-6.
:::

-   Which plots look like stationary time series?

-   Can you guess the model/source of $x_t$ from these plots?

-   How many trends have we estimated?

```{r}
#| message: false ## turn off to troubleshoot

## load (and possibly install) packages
library(astsa)
library(ggplot2)
#install.packages(forecast)
library(forecast)
# install.packages("patchwork")
library(patchwork)
library(tidyverse)

time_series <- read.csv(here::here('data', "time_series.csv"))

## your code here
ts_modeling <- function(df, x) {

  ts_data <- df[[x]]
  
  par(mfrow = c(2,3))
  
  # original time series
  tsplot(ts_data, type = 'p', main = paste("Original:", x), xlab = "Time", ylab = x)
  lines(ts_data)
  
  # moving average
  w = c(.5, rep(1,11), .5)/12
  x_ma = stats::filter(ts_data, sides=2, filter=w)
  tsplot(ts_data, type = 'p', main = paste("Moving Average:", x), xlab = "Time", ylab = x)
  lines(ts_data)
  lines(x_ma, col = 'firebrick')
  
  # detrend ma
  x_detrend <- ts_data - x_ma
  tsplot(x_detrend, type = 'p', main = paste("Detrended (MA):", x), xlab = "Time", ylab = "Detrended")
  lines(x_detrend)
  
  # slr
  x_slr <- lm(ts_data ~ time(ts_data))
  tsplot(ts_data, type = 'p', main = paste("Linear Fit:", x), xlab = "Time", ylab = x)
  lines(ts_data)
  abline(x_slr, col = 'firebrick')
  
  # detrend slr
  x_resid <- resid(x_slr)
  tsplot(x_resid, type = 'p', main = paste("Detrended (SLR):", x), xlab = "Time", ylab = "Residuals")
  lines(x_resid)
  
  # difference
  x_diff <- diff(ts_data)
  tsplot(x_diff, type = 'p', main = paste("Differenced:", x), xlab = "Time", ylab = "Difference")
  lines(x_diff)
  
  par(mfrow = c(1,1))

}
```

```{r}
#| message: false

map(colnames(time_series), ~ts_modeling(time_series, .x))
```

## Activity 3

Use the function `process_ts` to create the plots for the remaining series.

```{r}
source(here::here('functions', "process_ts.r"))
```

```{r}
process_ts(time_series$y1, ptitle = "TS1")

## fill in the rest of the series
map2(time_series, seq(1,5), ~process_ts(.x, ptitle = paste('TS', .y, sep='')))
```

## Activity 4

In steps 2-6 above, you generated 6 different time series for each raw series. Use the below code to plot the autocorrelation function on each of the series (plot the **sample** autocorrelation of each of the series).

```{r}
#| eval: true
source(here::here('functions', "plot_acfs.r"))
```

```{r}
plot_acfs(time_series$y1, main = "TS 1")
## fill in the rest
map2(time_series, seq(1,5), ~plot_acfs(.x, main = paste('TS', .y, sep='')))
```

1.  Which of the series looks like white noise?

2.  Which of the series looks like a moving average?

3.  Which of the series looks like there might be trend nonstationarity?

4.  Can you identify which type of time series $x_t$ is?

5.  For each of the 5 smoothed/detrended/differenced series, is the structure of the acf predictable based on the corresponding time series plot? If you had just seen the original data (i.e. the plot in number 1), would you be able to tell what the series was?
